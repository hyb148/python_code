{
 "metadata": {
  "name": "",
  "signature": "sha256:712c0370a2573490a8e7af14863888e3ff61468ebb0aa48390f906ea37bcbf6c"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import scipy as sp\n",
      "def llfun(act, pred):\n",
      "    epsilon = 1e-15\n",
      "    pred = sp.maximum(epsilon, pred)\n",
      "    pred = sp.minimum(1-epsilon, pred)\n",
      "    ll = sum(act*sp.log(pred) + sp.subtract(1,act)*sp.log(sp.subtract(1,pred)))\n",
      "    ll = ll * -1.0/len(act)\n",
      "    return ll\n",
      "\n",
      "import re\n",
      "path = r'../../_python_data\\Biological Response'\n",
      "path = re.sub(r\"\\\\\", \"/\", path)\n",
      "training_data_path = path + '/train.csv'\n",
      "test_data_path = path + '/test.csv'\n",
      "#read in  data, parse into training and target sets\n",
      "dataset = genfromtxt(open(training_data_path,'r'), delimiter=',', dtype='f8')[1:]    \n",
      "test = genfromtxt(open(test_data_path,'r'), delimiter=',', dtype='f8')[1:]\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#https://www.kaggle.com/wiki/GettingStartedWithPythonForDataScience\n",
      "from sklearn.ensemble import RandomForestClassifier\n",
      "from numpy import genfromtxt, savetxt\n",
      "\n",
      "def main():\n",
      "    #create the training & test sets, skipping the header row with [1:]\n",
      "    target = [x[0] for x in dataset]\n",
      "    train = [x[1:] for x in dataset]\n",
      "\n",
      "    #create and train the random forest\n",
      "    #multi-core CPUs can use: rf = RandomForestClassifier(n_estimators=100, n_jobs=2)\n",
      "    rf = RandomForestClassifier(n_estimators=100)\n",
      "    rf.fit(train, target)\n",
      "    predicted_probs = [[index + 1, x[1]] for index, x in enumerate(rf.predict_proba(test))]\n",
      "\n",
      "    savetxt('Data/submission.csv', predicted_probs, delimiter=',', fmt='%d,%f', \n",
      "            header='MoleculeId,PredictedProbability', comments = '')\n",
      "\n",
      "if __name__==\"__main__\":\n",
      "    main()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.ensemble import RandomForestClassifier\n",
      "from sklearn import cross_validation\n",
      "from sklearn.metrics import mean_squared_error,r2_score\n",
      "from sklearn import metrics\n",
      "import numpy as np\n",
      "\n",
      "def main():\n",
      "    target = np.array([x[0] for x in dataset])\n",
      "    train = np.array([x[1:] for x in dataset])\n",
      "    #In this case we'll use a random forest, but this could be any classifier\n",
      "    cfr = RandomForestClassifier(n_estimators=100)\n",
      "\n",
      "    #Simple K-Fold cross validation. 5 folds.\n",
      "    cv = cross_validation.KFold(len(train), n_folds=5)\n",
      "\n",
      "    #iterate through the training and test cross validation segments and\n",
      "    #run the classifier on each one, aggregating the results into a list\n",
      "    results = []\n",
      "    mse = []\n",
      "    r2 = []\n",
      "    for traincv, testcv in cv:\n",
      "        cfr.fit(train[traincv], target[traincv])\n",
      "        probas = cfr.predict_proba(train[testcv])\n",
      "        results.append(llfun(target[testcv], [x[1] for x in probas]) )\n",
      "        mse.append(mean_squared_error(target[testcv], [x[1] for x in probas]))\n",
      "        r2.append(r2_score(target[testcv], [x[1] for x in probas]))\n",
      "        \n",
      "        probas = cfr.predict(train[testcv])\n",
      "        print metrics.classification_report(target[testcv], probas,\n",
      "                                    target_names=['background', 'foreground'])\n",
      "        print \"accuracy:\", metrics.accuracy_score(target[testcv], probas)\n",
      "        print \"precision:\", metrics.precision_score(target[testcv], probas)\n",
      "        print \"recall:\", metrics.recall_score(target[testcv], probas)\n",
      "        print \"f1 score:\", metrics.f1_score(target[testcv], probas)\n",
      "        \n",
      "    #print out the mean of the cross-validated results\n",
      "    print \"Total K-Fold Results:\"\n",
      "    print \"LogLoss Results: \" + str( np.array(results).mean() )\n",
      "    print \"MSE Results: \" + str( np.array(mse).mean() )\n",
      "    print \"R2 Results: \" + str( np.array(r2).mean() )\n",
      "if __name__==\"__main__\":\n",
      "    main()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "             precision    recall  f1-score   support\n",
        "\n",
        " background       0.73      0.78      0.76       310\n",
        " foreground       0.84      0.80      0.82       441\n",
        "\n",
        "avg / total       0.79      0.79      0.79       751\n",
        "\n",
        "accuracy: 0.792276964048\n",
        "precision: 0.836879432624\n",
        "recall: 0.802721088435\n",
        "f1 score: 0.819444444444\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        " background       0.81      0.75      0.78       365\n",
        " foreground       0.78      0.84      0.81       385\n",
        "\n",
        "avg / total       0.79      0.79      0.79       750\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "accuracy: 0.793333333333\n",
        "precision: 0.777777777778\n",
        "recall: 0.836363636364\n",
        "f1 score: 0.806007509387\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        " background       0.72      0.78      0.75       331\n",
        " foreground       0.82      0.76      0.79       419\n",
        "\n",
        "avg / total       0.77      0.77      0.77       750\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "accuracy: 0.770666666667\n",
        "precision: 0.815856777494\n",
        "recall: 0.761336515513\n",
        "f1 score: 0.787654320988\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        " background       0.84      0.80      0.82       364\n",
        " foreground       0.82      0.86      0.84       386\n",
        "\n",
        "avg / total       0.83      0.83      0.83       750\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "accuracy: 0.830666666667\n",
        "precision: 0.821339950372\n",
        "recall: 0.857512953368\n",
        "f1 score: 0.839036755387\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        " background       0.78      0.77      0.78       347\n",
        " foreground       0.80      0.81      0.81       403\n",
        "\n",
        "avg / total       0.79      0.79      0.79       750\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "accuracy: 0.793333333333\n",
        "precision: 0.803921568627\n",
        "recall: 0.813895781638\n",
        "f1 score: 0.808877928483\n",
        "LogLoss Results: 0.458324027229\n",
        "MSE Results: 0.147373386773\n",
        "R2 Results: 0.404322574308\n"
       ]
      }
     ],
     "prompt_number": 52
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# follow up: http://stats.stackexchange.com/questions/7207/roc-vs-precision-and-recall-curves/7210"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.0 1\n"
       ]
      }
     ],
     "prompt_number": 39
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}