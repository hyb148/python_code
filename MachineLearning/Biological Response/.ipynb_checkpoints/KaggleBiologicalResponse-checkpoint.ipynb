{
 "metadata": {
  "name": "",
  "signature": "sha256:f3383ec4924b3535fe71668c81844c9bec0c49a6e9bbec47aceee5a732a551c8"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import scipy as sp\n",
      "def llfun(act, pred):\n",
      "    epsilon = 1e-15\n",
      "    pred = sp.maximum(epsilon, pred)\n",
      "    pred = sp.minimum(1-epsilon, pred)\n",
      "    ll = sum(act*sp.log(pred) + sp.subtract(1,act)*sp.log(sp.subtract(1,pred)))\n",
      "    ll = ll * -1.0/len(act)\n",
      "    return ll\n",
      "\n",
      "import re\n",
      "path = r'../../../_python_data\\Biological Response'\n",
      "path = re.sub(r\"\\\\\", \"/\", path)\n",
      "training_data_path = path + '/train.csv'\n",
      "test_data_path = path + '/test.csv'\n",
      "#read in  data, parse into training and target sets\n",
      "dataset = genfromtxt(open(training_data_path,'r'), delimiter=',', dtype='f8')[1:]    \n",
      "test = genfromtxt(open(test_data_path,'r'), delimiter=',', dtype='f8')[1:]\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# RFC Submission\n",
      "#https://www.kaggle.com/wiki/GettingStartedWithPythonForDataScience\n",
      "from sklearn.ensemble import RandomForestClassifier\n",
      "from numpy import genfromtxt, savetxt\n",
      "\n",
      "def main():\n",
      "    #create the training & test sets, skipping the header row with [1:]\n",
      "    target = [x[0] for x in dataset]\n",
      "    train = [x[1:] for x in dataset]\n",
      "\n",
      "    #create and train the random forest\n",
      "    #multi-core CPUs can use: rf = RandomForestClassifier(n_estimators=100, n_jobs=2)\n",
      "    rf = RandomForestClassifier(n_estimators=100)\n",
      "    rf.fit(train, target)\n",
      "    predicted_probs = [[index + 1, x[1]] for index, x in enumerate(rf.predict_proba(test))]\n",
      "\n",
      "    savetxt('RFC_submission.csv', predicted_probs, delimiter=',', fmt='%d,%f', \n",
      "            header='MoleculeId,PredictedProbability', comments = '')\n",
      "\n",
      "if __name__==\"__main__\":\n",
      "    main()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#RFC Cross Validation\n",
      "from sklearn.ensemble import RandomForestClassifier\n",
      "from sklearn import cross_validation\n",
      "from sklearn.metrics import mean_squared_error,r2_score\n",
      "from sklearn import metrics\n",
      "import numpy as np\n",
      "\n",
      "def main():\n",
      "    target = np.array([x[0] for x in dataset])\n",
      "    train = np.array([x[1:] for x in dataset])\n",
      "    #In this case we'll use a random forest, but this could be any classifier\n",
      "    cfr = RandomForestClassifier(n_estimators=100)\n",
      "\n",
      "    #Simple K-Fold cross validation. 5 folds.\n",
      "    cv = cross_validation.KFold(len(train), n_folds=5)\n",
      "\n",
      "    #iterate through the training and test cross validation segments and\n",
      "    #run the classifier on each one, aggregating the results into a list\n",
      "    results = []\n",
      "    mse = []\n",
      "    r2 = []\n",
      "    for traincv, testcv in cv:\n",
      "        cfr.fit(train[traincv], target[traincv])\n",
      "        probas = cfr.predict_proba(train[testcv])\n",
      "        results.append(llfun(target[testcv], [x[1] for x in probas]) )\n",
      "        mse.append(mean_squared_error(target[testcv], [x[1] for x in probas]))\n",
      "        r2.append(r2_score(target[testcv], [x[1] for x in probas]))\n",
      "        \n",
      "        probas = cfr.predict(train[testcv])\n",
      "        print metrics.classification_report(target[testcv], probas,\n",
      "                                    target_names=['background', 'foreground'])\n",
      "        print \"accuracy:\", metrics.accuracy_score(target[testcv], probas)\n",
      "        print \"precision:\", metrics.precision_score(target[testcv], probas)\n",
      "        print \"recall:\", metrics.recall_score(target[testcv], probas)\n",
      "        print \"f1 score:\", metrics.f1_score(target[testcv], probas)\n",
      "        \n",
      "    #print out the mean of the cross-validated results\n",
      "    print \"Total K-Fold Results:\"\n",
      "    print \"LogLoss Results: \" + str( np.array(results).mean() )\n",
      "    print \"MSE Results: \" + str( np.array(mse).mean() )\n",
      "    print \"R2 Results: \" + str( np.array(r2).mean() )\n",
      "if __name__==\"__main__\":\n",
      "    main()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "             precision    recall  f1-score   support\n",
        "\n",
        " background       0.73      0.78      0.76       310\n",
        " foreground       0.84      0.80      0.82       441\n",
        "\n",
        "avg / total       0.79      0.79      0.79       751\n",
        "\n",
        "accuracy: 0.792276964048\n",
        "precision: 0.836879432624\n",
        "recall: 0.802721088435\n",
        "f1 score: 0.819444444444\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        " background       0.81      0.75      0.78       365\n",
        " foreground       0.78      0.84      0.81       385\n",
        "\n",
        "avg / total       0.79      0.79      0.79       750\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "accuracy: 0.793333333333\n",
        "precision: 0.777777777778\n",
        "recall: 0.836363636364\n",
        "f1 score: 0.806007509387\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        " background       0.72      0.78      0.75       331\n",
        " foreground       0.82      0.76      0.79       419\n",
        "\n",
        "avg / total       0.77      0.77      0.77       750\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "accuracy: 0.770666666667\n",
        "precision: 0.815856777494\n",
        "recall: 0.761336515513\n",
        "f1 score: 0.787654320988\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        " background       0.84      0.80      0.82       364\n",
        " foreground       0.82      0.86      0.84       386\n",
        "\n",
        "avg / total       0.83      0.83      0.83       750\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "accuracy: 0.830666666667\n",
        "precision: 0.821339950372\n",
        "recall: 0.857512953368\n",
        "f1 score: 0.839036755387\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        " background       0.78      0.77      0.78       347\n",
        " foreground       0.80      0.81      0.81       403\n",
        "\n",
        "avg / total       0.79      0.79      0.79       750\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "accuracy: 0.793333333333\n",
        "precision: 0.803921568627\n",
        "recall: 0.813895781638\n",
        "f1 score: 0.808877928483\n",
        "LogLoss Results: 0.458324027229\n",
        "MSE Results: 0.147373386773\n",
        "R2 Results: 0.404322574308\n"
       ]
      }
     ],
     "prompt_number": 52
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# follow up: http://stats.stackexchange.com/questions/7207/roc-vs-precision-and-recall-curves/7210"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.0 1\n"
       ]
      }
     ],
     "prompt_number": 39
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# GBM Cross Validation\n",
      "from sklearn import ensemble\n",
      "from sklearn import cross_validation\n",
      "from sklearn.metrics import mean_squared_error,r2_score\n",
      "from sklearn import metrics\n",
      "import numpy as np\n",
      "\n",
      "\n",
      "def main():\n",
      "    print('Running GradientBoostingRegressor')\n",
      "    target = np.array([x[0] for x in dataset])\n",
      "    train = np.array([x[1:] for x in dataset])\n",
      "    \n",
      "    \"\"\"\n",
      "    params = {'n_estimators': 500, 'max_depth': 4, 'min_samples_split': 1,\n",
      "          'learning_rate': 0.01, 'loss': 'ls'}\n",
      "    model = ensemble.GradientBoostingRegression(**params)\n",
      "    \"\"\"\n",
      "    params = {'n_estimators': 500, 'max_depth': 4, 'min_samples_split': 1,\n",
      "          'learning_rate': 0.01}\n",
      "    model = ensemble.GradientBoostingClassifier(**params)\n",
      "\n",
      "    #Simple K-Fold cross validation. 5 folds.\n",
      "    cv = cross_validation.KFold(len(train), n_folds=5)\n",
      "\n",
      "    #iterate through the training and test cross validation segments and\n",
      "    #run the classifier on each one, aggregating the results into a list\n",
      "    results = []\n",
      "    mse = []\n",
      "    r2 = []\n",
      "    for traincv, testcv in cv:\n",
      "        model.fit(train[traincv], target[traincv])\n",
      "        #probas = cfr.predict_proba(train[testcv])\n",
      "        probas = model.predict(train[testcv])\n",
      "        results.append(llfun(target[testcv], probas) )\n",
      "        mse.append(mean_squared_error(target[testcv], probas))\n",
      "        r2.append(r2_score(target[testcv], probas))\n",
      "        \n",
      "        print metrics.classification_report(target[testcv], probas,\n",
      "                                    target_names=['background', 'foreground'])\n",
      "        print \"accuracy:\", metrics.accuracy_score(target[testcv], probas)\n",
      "        print \"precision:\", metrics.precision_score(target[testcv], probas)\n",
      "        print \"recall:\", metrics.recall_score(target[testcv], probas)\n",
      "        print \"f1 score:\", metrics.f1_score(target[testcv], probas)\n",
      "        \n",
      "    #print out the mean of the cross-validated results\n",
      "    print \"Total K-Fold Results for GBR:\"\n",
      "    print \"LogLoss Results: \" + str( np.array(results).mean() )\n",
      "    print \"MSE Results: \" + str( np.array(mse).mean() )\n",
      "    print \"R2 Results: \" + str( np.array(r2).mean() )\n",
      "if __name__==\"__main__\":\n",
      "    main()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Running GradientBoostingRegressor\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        " background       0.74      0.75      0.75       310\n",
        " foreground       0.82      0.82      0.82       441\n",
        "\n",
        "avg / total       0.79      0.79      0.79       751\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "accuracy: 0.789613848202\n",
        "precision: 0.822323462415\n",
        "recall: 0.818594104308\n",
        "f1 score: 0.820454545455\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        " background       0.83      0.72      0.77       365\n",
        " foreground       0.76      0.86      0.81       385\n",
        "\n",
        "avg / total       0.80      0.79      0.79       750\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "accuracy: 0.792\n",
        "precision: 0.763218390805\n",
        "recall: 0.862337662338\n",
        "f1 score: 0.809756097561\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        " background       0.74      0.75      0.74       331\n",
        " foreground       0.80      0.79      0.79       419\n",
        "\n",
        "avg / total       0.77      0.77      0.77       750\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "accuracy: 0.772\n",
        "precision: 0.800970873786\n",
        "recall: 0.787589498807\n",
        "f1 score: 0.794223826715\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        " background       0.82      0.74      0.78       364\n",
        " foreground       0.78      0.84      0.81       386\n",
        "\n",
        "avg / total       0.80      0.79      0.79       750\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "accuracy: 0.794666666667\n",
        "precision: 0.77619047619\n",
        "recall: 0.844559585492\n",
        "f1 score: 0.808933002481\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        " background       0.81      0.73      0.76       347\n",
        " foreground       0.78      0.85      0.82       403\n",
        "\n",
        "avg / total       0.79      0.79      0.79       750\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "accuracy: 0.793333333333\n",
        "precision: 0.783105022831\n",
        "recall: 0.85111662531\n",
        "f1 score: 0.815695600476\n",
        "Total K-Fold Results for GBR:\n",
        "LogLoss Results: 7.31116888328\n",
        "MSE Results: 0.21167723036\n",
        "R2 Results: 0.144276216258\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# GBC Submission\n",
      "\n",
      "target = np.array([x[0] for x in dataset])\n",
      "train = np.array([x[1:] for x in dataset])\n",
      "\n",
      "params = {'n_estimators': 500, 'max_depth': 4, 'min_samples_split': 1,\n",
      "      'learning_rate': 0.01}\n",
      "model = ensemble.GradientBoostingClassifier(**params)\n",
      "\n",
      "y_test = model.predict(test)\n",
      "predicted_probs = [[index + 1, x] for index, x in enumerate(y_test)]\n",
      "savetxt('GBC_submission.csv', predicted_probs, delimiter=',', fmt='%d,%f', \n",
      "        header='MoleculeId,PredictedProbability', comments = '')\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'probas' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-8-31065c6fb9fd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprobas\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[1;31mNameError\u001b[0m: name 'probas' is not defined"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}